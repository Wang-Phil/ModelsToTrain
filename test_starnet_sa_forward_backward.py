"""
æµ‹è¯• StarNet SA å˜ä½“æ¨¡å‹çš„å‰å‘ä¼ æ’­å’Œåå‘ä¼ æ’­
"""

import torch
import torch.nn as nn
import sys
import os

# æ·»åŠ æ¨¡å‹è·¯å¾„
sys.path.insert(0, os.path.join(os.path.dirname(__file__), 'models'))

from starnet_sa_variants import (
    starnet_sa_s1,
    starnet_sa_s2,
    starnet_sa_s3,
    starnet_sa_s4,
    StarNet_SA
)

def test_model_forward_backward(model, model_name, device='cuda' if torch.cuda.is_available() else 'cpu'):
    """
    æµ‹è¯•æ¨¡å‹çš„å‰å‘ä¼ æ’­å’Œåå‘ä¼ æ’­
    
    Args:
        model: æ¨¡å‹å®ä¾‹
        model_name: æ¨¡å‹åç§°
        device: è®¾å¤‡ ('cuda' æˆ– 'cpu')
    """
    print(f"\n{'='*60}")
    print(f"æµ‹è¯•æ¨¡å‹: {model_name}")
    print(f"è®¾å¤‡: {device}")
    print(f"{'='*60}")
    
    model = model.to(device)
    model.train()  # è®¾ç½®ä¸ºè®­ç»ƒæ¨¡å¼ä»¥å¯ç”¨dropoutç­‰
    
    # åˆ›å»ºæµ‹è¯•è¾“å…¥
    batch_size = 2
    input_size = 224
    x = torch.randn(batch_size, 3, input_size, input_size).to(device)
    
    try:
        # 1. æµ‹è¯•å‰å‘ä¼ æ’­
        print("\n[1] æµ‹è¯•å‰å‘ä¼ æ’­...")
        with torch.no_grad():
            output = model(x)
        print(f"    âœ“ å‰å‘ä¼ æ’­æˆåŠŸ!")
        print(f"    è¾“å…¥å½¢çŠ¶: {x.shape}")
        print(f"    è¾“å‡ºå½¢çŠ¶: {output.shape}")
        print(f"    è¾“å‡ºèŒƒå›´: [{output.min().item():.4f}, {output.max().item():.4f}]")
        
        # æ£€æŸ¥è¾“å‡ºæ˜¯å¦åŒ…å« NaN æˆ– Inf
        if torch.isnan(output).any():
            print(f"    âœ— è­¦å‘Š: è¾“å‡ºåŒ…å« NaN!")
            return False
        if torch.isinf(output).any():
            print(f"    âœ— è­¦å‘Š: è¾“å‡ºåŒ…å« Inf!")
            return False
        
        # 2. æµ‹è¯•åå‘ä¼ æ’­
        print("\n[2] æµ‹è¯•åå‘ä¼ æ’­...")
        model.zero_grad()
        output = model(x)  # é‡æ–°å‰å‘ä¼ æ’­ï¼ˆä¸ä½¿ç”¨no_gradï¼‰
        
        # åˆ›å»ºè™šæ‹ŸæŸå¤±
        target = torch.randint(0, model.num_classes, (batch_size,)).to(device)
        criterion = nn.CrossEntropyLoss()
        loss = criterion(output, target)
        
        print(f"    Losså€¼: {loss.item():.4f}")
        
        # åå‘ä¼ æ’­
        loss.backward()
        print(f"    âœ“ åå‘ä¼ æ’­æˆåŠŸ!")
        
        # æ£€æŸ¥æ¢¯åº¦
        has_grad = False
        no_grad_count = 0
        total_params = 0
        
        for name, param in model.named_parameters():
            total_params += 1
            if param.grad is not None:
                has_grad = True
                grad_norm = param.grad.norm().item()
                if torch.isnan(param.grad).any():
                    print(f"    âœ— è­¦å‘Š: {name} çš„æ¢¯åº¦åŒ…å« NaN!")
                    return False
                if torch.isinf(param.grad).any():
                    print(f"    âœ— è­¦å‘Š: {name} çš„æ¢¯åº¦åŒ…å« Inf!")
                    return False
            else:
                no_grad_count += 1
        
        print(f"    æ€»å‚æ•°æ•°é‡: {total_params}")
        print(f"    æœ‰æ¢¯åº¦çš„å‚æ•°: {total_params - no_grad_count}")
        print(f"    æ— æ¢¯åº¦çš„å‚æ•°: {no_grad_count}")
        
        if not has_grad:
            print(f"    âœ— è­¦å‘Š: æ²¡æœ‰ä»»ä½•å‚æ•°æœ‰æ¢¯åº¦!")
            return False
        
        # 3. æµ‹è¯•ä¸åŒè¾“å…¥å°ºå¯¸
        print("\n[3] æµ‹è¯•ä¸åŒè¾“å…¥å°ºå¯¸...")
        test_sizes = [(1, 3, 224, 224), (4, 3, 256, 256), (2, 3, 112, 112)]
        for size in test_sizes:
            try:
                x_test = torch.randn(*size).to(device)
                with torch.no_grad():
                    output_test = model(x_test)
                print(f"    âœ“ è¾“å…¥å°ºå¯¸ {size} -> è¾“å‡ºå½¢çŠ¶ {output_test.shape}")
            except Exception as e:
                print(f"    âœ— è¾“å…¥å°ºå¯¸ {size} å¤±è´¥: {e}")
                return False
        
        print(f"\nâœ“ {model_name} æµ‹è¯•é€šè¿‡!")
        return True
        
    except Exception as e:
        print(f"\nâœ— {model_name} æµ‹è¯•å¤±è´¥!")
        print(f"   é”™è¯¯ä¿¡æ¯: {str(e)}")
        import traceback
        traceback.print_exc()
        return False


def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("="*60)
    print("StarNet SA å˜ä½“æ¨¡å‹å‰å‘/åå‘ä¼ æ’­æµ‹è¯•")
    print("="*60)
    
    device = 'cuda' if torch.cuda.is_available() else 'cpu'
    print(f"\nä½¿ç”¨è®¾å¤‡: {device}")
    if torch.cuda.is_available():
        print(f"GPU: {torch.cuda.get_device_name(0)}")
        print(f"CUDAç‰ˆæœ¬: {torch.version.cuda}")
    
    # æµ‹è¯•æ‰€æœ‰æ¨¡å‹å˜ä½“
    models_to_test = [
        (starnet_sa_s1, "starnet_sa_s1"),
        (starnet_sa_s2, "starnet_sa_s2"),
        (starnet_sa_s3, "starnet_sa_s3"),
        (starnet_sa_s4, "starnet_sa_s4"),
    ]
    
    results = {}
    for model_fn, model_name in models_to_test:
        try:
            model = model_fn(pretrained=False, num_classes=1000)
            success = test_model_forward_backward(model, model_name, device)
            results[model_name] = success
        except Exception as e:
            print(f"\nâœ— {model_name} å®ä¾‹åŒ–å¤±è´¥: {e}")
            results[model_name] = False
            import traceback
            traceback.print_exc()
    
    # æ‰“å°æ€»ç»“
    print("\n" + "="*60)
    print("æµ‹è¯•æ€»ç»“")
    print("="*60)
    for model_name, success in results.items():
        status = "âœ“ é€šè¿‡" if success else "âœ— å¤±è´¥"
        print(f"{model_name}: {status}")
    
    all_passed = all(results.values())
    if all_passed:
        print("\nğŸ‰ æ‰€æœ‰æ¨¡å‹æµ‹è¯•é€šè¿‡!")
    else:
        print("\nâš ï¸  éƒ¨åˆ†æ¨¡å‹æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥ä¸Šè¿°é”™è¯¯ä¿¡æ¯")
    
    return all_passed


if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)

