# å¼•å…¥å¿…è¦çš„åº“
import torch
import sys
import os # å¯¼å…¥ os åº“ä»¥ä¾¿æ›´æ¸…æ™°åœ°å¤„ç†è·¯å¾„

# è®¾ç½®è·¯å¾„ï¼ˆå‡è®¾æ‚¨çš„æ¨¡å‹æ–‡ä»¶ä½äºè¿™ä¸ªè·¯å¾„ä¸‹ï¼‰
sys.path.insert(0, '/home/ln/wangweicheng/ModelsTotrain')

# --- GPU/CUDA æ£€æµ‹ä¸è®¾ç½® ---
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

print("=" * 80)
print("æ£€æŸ¥ starnet_dual_pyramid_rcf æ¨¡å‹")
print(f"ğŸš€ å½“å‰è¿è¡Œè®¾å¤‡: {device}")
if device.type == 'cuda':
    print(f"   CUDA è®¾å¤‡åç§°: {torch.cuda.get_device_name(0)}")
print("=" * 80)

try:
    # å‡è®¾æ‚¨çš„æ¨¡å‹æ–‡ä»¶åä¸º starnet_dual_pyramid_rcf.py ä¸”å·²åœ¨è·¯å¾„ä¸­
    from models.starnet_dual_pyramid_rcf import starnet_dual_pyramid_rcf, StarNet_DualPyramid_RCF
    
    # 1. æµ‹è¯•æ¨¡å‹åˆ›å»ºå¹¶ç§»åŠ¨åˆ°è®¾å¤‡
    print("\n1. æµ‹è¯•æ¨¡å‹åˆ›å»º...")
    # å®ä¾‹åŒ–æ¨¡å‹ï¼Œå¹¶ä½¿ç”¨ .to(device) å°†å…¶ç§»åŠ¨åˆ° GPU æˆ– CPU
    model = starnet_dual_pyramid_rcf(num_classes=9).to(device)
    print("   âœ“ æ¨¡å‹åˆ›å»ºæˆåŠŸå¹¶å·²ç§»åŠ¨åˆ°è®¾å¤‡")
    
    # 2. æ£€æŸ¥æ¨¡å‹ç»“æ„ (ä¿æŒä¸å˜)
    print("\n2. æ£€æŸ¥æ¨¡å‹ç»“æ„...")
    print(f"   - Local Pyramid downsamples: {len(model.local.downsamples)}")
    print(f"   - Local Pyramid blocks_list: {len(model.local.blocks_list)}")
    print(f"   - Global Pyramid stages: {len(model.global_pyr.stages)}")
    print(f"   - Adapters: {len(model.adapters)}")
    print(f"   - Fuse weights: {len(model.fuse_weights)}")
    print(f"   - Gamma weights: {len(model.gamma_weights)}")
    
    # 3. æµ‹è¯•å‰å‘ä¼ æ’­
    print("\n3. æµ‹è¯•å‰å‘ä¼ æ’­...")
    # åˆ›å»ºè¾“å…¥å¼ é‡ï¼Œå¹¶ä½¿ç”¨ .to(device) å°†å…¶ç§»åŠ¨åˆ°ä¸æ¨¡å‹ç›¸åŒçš„è®¾å¤‡
    x = torch.randn(2, 3, 224, 224, device=device) # ç›´æ¥åœ¨è®¾å¤‡ä¸Šåˆ›å»ºå¼ é‡
    
    # ç¡®ä¿æ¨¡å‹å¤„äºè¯„ä¼°æ¨¡å¼ï¼ˆè™½ç„¶æµ‹è¯•æ—¶å½±å“ä¸å¤§ï¼Œä½†é€šå¸¸æ˜¯å¥½ä¹ æƒ¯ï¼‰
    model.eval() 
    
    # ä½¿ç”¨ torch.no_grad() åŒ…è£¹ï¼Œé¿å…åœ¨æµ‹è¯•æ—¶è®¡ç®—æ¢¯åº¦ï¼ŒèŠ‚çœå†…å­˜å’Œæ—¶é—´
    with torch.no_grad():
        output = model(x)
        
    print(f"   âœ“ å‰å‘ä¼ æ’­æˆåŠŸ")
    # æ£€æŸ¥è¾“å‡ºå½¢çŠ¶ï¼Œè¾“å‡ºä¹Ÿåº”è¯¥åœ¨ device ä¸Š
    print(f"   - è¾“å‡ºå½¢çŠ¶: {output.shape}")
    print(f"   - è¾“å‡ºè®¾å¤‡: {output.device}")
    
    # 4. æ£€æŸ¥å‚æ•°é‡ (ä¿æŒä¸å˜)
    print("\n4. æ£€æŸ¥å‚æ•°é‡...")
    total_params = sum(p.numel() for p in model.parameters())
    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
    print(f"   - æ€»å‚æ•°é‡: {total_params / 1e6:.2f}M")
    print(f"   - å¯è®­ç»ƒå‚æ•°: {trainable_params / 1e6:.2f}M")
    
    # 5. æµ‹è¯•æ¢¯åº¦åå‘ä¼ æ’­
    print("\n5. æµ‹è¯•æ¢¯åº¦åå‘ä¼ æ’­...")
    model.train() # åˆ‡æ¢å›è®­ç»ƒæ¨¡å¼
    
    # é‡æ–°è¿›è¡Œå‰å‘ä¼ æ’­ä»¥è®¡ç®—æ¢¯åº¦ (å› ä¸ºç¬¬3æ­¥ä½¿ç”¨äº† torch.no_grad())
    x = torch.randn(2, 3, 224, 224, device=device)
    output = model(x)
    
    # æŸå¤±å‡½æ•°å’Œæ ‡ç­¾ä¹Ÿè¦ç§»åŠ¨åˆ°è®¾å¤‡
    criterion = torch.nn.CrossEntropyLoss()
    labels = torch.randint(0, 9, (2,)).to(device)
    
    loss = criterion(output, labels)
    loss.backward()
    print(f"   âœ“ åå‘ä¼ æ’­æˆåŠŸ (Loss: {loss.item():.4f})")
    
    print("\n" + "=" * 80)
    print("âœ… æ¨¡å‹å¯ä»¥æ­£å¸¸åŠ è½½å’Œä½¿ç”¨ï¼")
    print("=" * 80)
    
except Exception as e:
    print(f"\nâŒ é”™è¯¯: {e}")
    import traceback
    traceback.print_exc()
    exit(1)